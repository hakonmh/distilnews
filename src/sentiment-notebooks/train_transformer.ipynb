{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Hugginface Transformer\n",
    "\n",
    "Trains Transformers from huggingface on the sentiment dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To allow importing modules from src\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the 'src' directory\n",
    "src_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "# Add 'src' directory to the Python path\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import itertools\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils import tensorboard as tb  # To run: tensorboard --logdir=runs\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_scheduler\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from lr_finder import LRFinder\n",
    "from helpers import (\n",
    "    SentimentDataset, SENTIMENT_TO_ID, ID_TO_SENTIMENT, \n",
    "    save_model, load_model, test_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Which transformer model to use? Alternatives: \"albert-base-v2\", \"albert-large-v2\", \"bert-large-uncased\"\n",
    "# \"roberta-base\", \"distilbert-base-uncased\", \"facebook/bart-base\", \"google/fnet-base\", \"bert-base-uncased\"\n",
    "MODEL_NAME = \"distilbert-base-uncased\"  \n",
    "MAX_LEN = 35  # Sentence length for padding\n",
    "\n",
    "NUM_EPOCHS = 3\n",
    "LR = 10e-5\n",
    "WEIGHT_DECAY = 10e-5\n",
    "BATCH_SIZE = 50\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "now = datetime.datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "file_name = f'{os.path.basename(MODEL_NAME)}-sentiment {now}'\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(batch, tokenizer, max_length=25):\n",
    "    \"\"\"Process a batch of data to its proper form.\"\"\"\n",
    "    # Feature should be batch_size * num_words * num_vocabs\n",
    "    features, labels = zip(*batch)\n",
    "    features = tokenizer(features, add_special_tokens=True, max_length=max_length, \n",
    "                         padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    labels = torch.stack(labels)\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, optimizer, train_loader, test_loader, writer, num_epochs, \n",
    "    scheduler=None, criterion=None, device='cuda', start_iter=0\n",
    "):\n",
    "    test_iter = itertools.cycle(iter(test_loader))\n",
    "    num_batches = len(train_loader)\n",
    "    writer.add_text('Hyperparameters', f'num_epochs: {num_epochs}, num_batches: {num_batches}')\n",
    "\n",
    "    progress_bar = tqdm(range(num_epochs*num_batches))\n",
    "    epoch_bar = tqdm(range(num_epochs))\n",
    "    for epoch in range(0, num_epochs):\n",
    "        batch_idx = 0\n",
    "        for train_batch in train_loader:\n",
    "            train_loss, train_accuracy = _train_one_round(train_batch, model, optimizer, \n",
    "                                                          scheduler, criterion, device)\n",
    "\n",
    "            if batch_idx % 10 == 0:\n",
    "                test_batch = next(test_iter)\n",
    "                test_loss, test_accuracy = _evaluate_one_round(test_batch, model, device)\n",
    "                gradient_norm = _get_gradient_norm(model)\n",
    "                lr = _get_learning_rate(optimizer, scheduler)\n",
    "\n",
    "                n_iter = batch_idx + num_batches * epoch + start_iter\n",
    "                _write_to_tboard(writer, n_iter, train_loss, test_loss, train_accuracy, \n",
    "                                 test_accuracy, gradient_norm, lr)\n",
    "            batch_idx += 1\n",
    "            progress_bar.update(1)\n",
    "        epoch_bar.update(1)\n",
    "\n",
    "\n",
    "def _train_one_round(batch, model, optimizer, scheduler=None, criterion=None, device='cuda'):\n",
    "    optimizer.zero_grad()\n",
    "    features, targets = batch\n",
    "    features = features.to(device=device)\n",
    "    targets = targets.to(device=device)\n",
    "\n",
    "    output = model(**features, labels=targets)\n",
    "    if criterion:\n",
    "        loss = criterion(output.logits, targets)\n",
    "    else:\n",
    "        loss = output.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    accuracy = _accuracy(output, targets)\n",
    "    del features, targets, output\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def _evaluate_one_round(batch, model, device='cuda'):\n",
    "    features, targets = batch\n",
    "    features = features.to(device=device)\n",
    "    targets = targets.to(device=device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**features, labels=targets)\n",
    "        loss = output.loss\n",
    "        accuracy = _accuracy(output, targets)\n",
    "    del features, targets, output\n",
    "    return loss, accuracy\n",
    "\n",
    "\n",
    "def _accuracy(output, target):\n",
    "    with torch.no_grad():\n",
    "        logits = output.logits\n",
    "        probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "        accuracy = (probs.argmax(dim=1) == target).sum().item() / len(target)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def _get_gradient_norm(model):\n",
    "    \"\"\"Computes the gradient norm of a model. I.e. the sum of the size of all gradients\"\"\"\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        param_norm = p.grad.norm(2)\n",
    "        total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** 0.5\n",
    "    return total_norm\n",
    "\n",
    "\n",
    "def _get_learning_rate(optimizer, scheduler):\n",
    "    if scheduler:\n",
    "        lr = torch.log10(torch.tensor(scheduler.get_last_lr()[0])).item()\n",
    "    else:\n",
    "        lr = torch.log10(torch.tensor(optimizer.param_groups[0]['lr'])).item()\n",
    "    return lr\n",
    "\n",
    "\n",
    "def _write_to_tboard(writer, n_iter, train_loss, test_loss, \n",
    "                     train_accuracy, test_accuracy, gradient_norm, lr=None):\n",
    "    writer.add_scalar('Train loss', train_loss, n_iter)\n",
    "    writer.add_scalar('Test loss', test_loss, n_iter)\n",
    "    writer.add_scalar('Train accuracy', train_accuracy, n_iter)\n",
    "    writer.add_scalar('Test accuracy', test_accuracy, n_iter)\n",
    "    writer.add_scalar('Gradient norm', gradient_norm, n_iter)\n",
    "    if lr:\n",
    "        writer.add_scalar('Log learning rate', lr, n_iter)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding=\"max_length\", truncation=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME, num_labels=3, id2label=ID_TO_SENTIMENT, label2id=SENTIMENT_TO_ID\n",
    ")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = SentimentDataset('../../data/fixed-data/sentiment-train.csv')\n",
    "test_set = SentimentDataset('../../data/fixed-data/sentiment-val.csv')\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                          collate_fn=lambda x: collate_batch(x, tokenizer, max_length=MAX_LEN))\n",
    "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True, \n",
    "                         collate_fn=lambda x: collate_batch(x, tokenizer, max_length=MAX_LEN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.000475744112974792"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-8, weight_decay=WEIGHT_DECAY)\n",
    "lrfinder = LRFinder(model, optimizer, criterion=None, device=device)\n",
    "lrfinder.run(train_loader, init_value=1e-8, final_value=1, beta=0.02)\n",
    "best_lr = lrfinder.plot()\n",
    "lrfinder.reset()\n",
    "best_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651db1f6d8e440f8af150a94e7e639d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21216 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f00d05ac59e48108ed708933be5238e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\", \n",
    "    optimizer=optimizer, \n",
    "    num_warmup_steps=0, \n",
    "    num_training_steps=NUM_EPOCHS * len(train_loader)\n",
    ")\n",
    "\n",
    "writer = tb.SummaryWriter(f'../../runs/{file_name}')\n",
    "train_model(model, optimizer, scheduler=lr_scheduler, criterion=None,\n",
    "            num_epochs=NUM_EPOCHS, train_loader=train_loader, test_loader=test_loader, \n",
    "            device=device, writer=writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing and Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, f'../../models/{file_name}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test size: 15518\n",
      "Baseline accuracy: 35.53 %\n",
      "Accuracy: 82.10 %\n"
     ]
    }
   ],
   "source": [
    "test_accuracy(model, test_loader, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label vs model prediction\n",
      "- Positive: Neutral\n",
      "- Neutral: Neutral\n",
      "- Negative: Negative\n"
     ]
    }
   ],
   "source": [
    "def predict_str(model, sentence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = sentence_pipeline(sentence)\n",
    "        tokens = tokens.to(device=device)\n",
    "        preds = model(**tokens)\n",
    "        probs = torch.nn.functional.softmax(preds.logits, dim=1)\n",
    "        yhat = probs.argmax(dim=1)\n",
    "        return ID_TO_SENTIMENT[yhat.item()]\n",
    "    \n",
    "\n",
    "def sentence_pipeline(sentence):\n",
    "    sentence = _clean_text(sentence)\n",
    "    features = tokenizer([sentence], add_special_tokens=True, max_length=MAX_LEN, \n",
    "                         padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
    "    return features\n",
    "    \n",
    "\n",
    "def _clean_text(headline: str):\n",
    "    headline = str(headline).lower()\n",
    "    headline = re.sub(r'[^a-zA-Z0-9.,?!-]', ' ', headline)\n",
    "    headline = re.sub(r'\\s+', ' ', headline)\n",
    "    headline = re.sub('- analyst blog', '', headline)\n",
    "    headline = headline.strip()\n",
    "    return headline\n",
    "\n",
    "pos = predict_str(model, \"Inflation stable as the stock market rises to an all time high\")\n",
    "neu = predict_str(model, \"Stock market finished side-ways for the day as GDP reports are released\")\n",
    "neg = predict_str(model, \"Inflation rampant as stocks keep crashing\")\n",
    "print(f\"Label vs model prediction\\n- Positive: {pos}\\n- Neutral: {neu}\\n- Negative: {neg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load a previously saved model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=3)\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, padding=\"max_length\", truncation=True)\n",
    "model = load_model(model, '../../models/distilbert-base-uncased 2023-05-05 11-17-06.pth', device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
